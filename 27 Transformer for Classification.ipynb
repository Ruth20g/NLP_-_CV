{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa86df52",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757b146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106866d",
   "metadata": {},
   "source": [
    "### Define Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1151f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att= MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn= Sequential([Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),])\n",
    "        \n",
    "        self.layernorm1=LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2= LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1=Dropout(rate)\n",
    "        self.dropout2=Dropout(rate)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        attn_output= self.att(inputs, inputs)\n",
    "        \n",
    "        attn_output= self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        out1= self.layernorm1(inputs+attn_output)\n",
    "        \n",
    "        ffn_output= self.ffn(out1)\n",
    "        \n",
    "        ffn_output= self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        return self.layernorm2(out1+ ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b73df65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb= Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        \n",
    "        self.pos_emb= Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "        \n",
    "    def call(self,x):\n",
    "        maxlen= tf.shape(x)[-1]\n",
    "        \n",
    "        positions= tf.range(start=0, limit=maxlen, delta=1)\n",
    "        \n",
    "        positions= self.pos_emb(positions)\n",
    "        \n",
    "        x= self.token_emb(x)\n",
    "        \n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f85a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= 2000\n",
    "maxlen=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6e3ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training Sequences\n",
      "25000 Validation Sequences\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val) = imdb.load_data(num_words= vocab_size)\n",
    "print(len(x_train), \"Training Sequences\")\n",
    "print(len(x_val), \"Validation Sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5aa6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "640eaa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b45801f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  89,    8,  511,    2,   59,    2,   41,  523,  147, 1876,    5,\n",
       "          2,  175,  347,   11,  618,    4,  172,   96,    2,    2,    9,\n",
       "        862,    2,    8,   41,    5,   27,  532,    2,    9,    2,    4,\n",
       "          2,  136,    2,    2,    5,    2,   19, 1456,  921,   42,    2,\n",
       "       1488,   68,    2,  216,   17,    6,    2,   48,   13,   69,    6,\n",
       "          2,   13,   62,   28,    2,   12,    8,   98,  634,  908,   10,\n",
       "         10,    2,    2,    9,    2,   17,    2,    6,   87, 1465,   48,\n",
       "         25,  377,   27,  478,  157,   11,    2,    2,   29,    2,    4,\n",
       "          2,    7,    2,    2,   83,    6,    2,    2,    7,  107,   42,\n",
       "        289,  715,  257,    5,   95,    2,    4,    2,   11,   17,    2,\n",
       "          5,    2, 1377,   17,  614,   11,   14,  365, 1652,    2,    2,\n",
       "        373,   10,   10,    4,  167,    2,    2,  287,   64,   35,    2,\n",
       "          2,    7, 1489,    4,  370,  121,   12,   80,  123,  178,   51,\n",
       "         75,  181,    8,   67,    4,  636,    2,    9,    2,    2,  190,\n",
       "         50,    9,  486,   54,   11,    6,  303,  548,    2,  684,    2,\n",
       "          2,  208,   11,    4,    2,    2,   95,    2,    4,    2,    2,\n",
       "        190,  122,   15,   79,  143,   10,   10, 1479, 1468,    9,    6,\n",
       "        196,  297,   14,  310,    9,   24, 1178,   18,    2,  361,   42,\n",
       "         76,  334])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c8fd9",
   "metadata": {},
   "source": [
    "### Combine all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dbc5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "num_heads=2\n",
    "ff_dim=32\n",
    "\n",
    "inputs=Input(shape=(maxlen,))\n",
    "embedding_layer= TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x= embedding_layer(inputs)\n",
    "transformer_block= TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x=transformer_block(x)\n",
    "x= GlobalAveragePooling1D()(x)\n",
    "x=Dropout(0.1)(x)\n",
    "x= Dense(20, activation=\"relu\")(x)\n",
    "x= Dropout(0.1)(x)\n",
    "outputs= Dense(2, activation='softmax')(x)\n",
    "\n",
    "model= Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e2f22df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " token_and_position_embeddi  (None, 200, 32)           70400     \n",
      " ng_2 (TokenAndPositionEmbe                                      \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " transformer_block_2 (Trans  (None, 200, 32)           10656     \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 32)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                660       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81758 (319.37 KB)\n",
      "Trainable params: 81758 (319.37 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ec9a244",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_model() got an unexpected keyword argument 'show_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m----> 2\u001b[0m plot_model(model, show_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_activations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      3\u001b[0m           show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_model() got an unexpected keyword argument 'show_type'"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, show_type=True, show_layer_activations=True,\n",
    "          show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335b307",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b172160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss= \"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3ab676",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39585ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "782/782 [==============================] - 34s 39ms/step - loss: 0.4174 - accuracy: 0.8016 - val_loss: 0.3879 - val_accuracy: 0.8363\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.2999 - accuracy: 0.8757 - val_loss: 0.3005 - val_accuracy: 0.8709\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.2800 - accuracy: 0.8858 - val_loss: 0.3101 - val_accuracy: 0.8689\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.2720 - accuracy: 0.8877 - val_loss: 0.3161 - val_accuracy: 0.8687\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.2647 - accuracy: 0.8911 - val_loss: 0.3181 - val_accuracy: 0.8614\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.2564 - accuracy: 0.8933 - val_loss: 0.3129 - val_accuracy: 0.8650\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.2481 - accuracy: 0.8951 - val_loss: 0.3510 - val_accuracy: 0.8608\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.2387 - accuracy: 0.8967 - val_loss: 0.3638 - val_accuracy: 0.8635\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.2302 - accuracy: 0.8978 - val_loss: 0.3616 - val_accuracy: 0.8633\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 30s 39ms/step - loss: 0.2167 - accuracy: 0.9020 - val_loss: 0.3798 - val_accuracy: 0.8604\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x_train, y_train, batch_size=32, epochs=10,\n",
    "                 validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b174a",
   "metadata": {},
   "source": [
    "### Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe21e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
